8f4e/v1

comment
; @pos -185 -19

; Mapping from the
; drawing grid to the
; neural network's input
; layer

commentEnd

comment
; @pos -326 27
; This project implements a feedforward
; neural network that maps a 3x5 binary 
; drawing grid into 15 inputs, runs them
; through multiple sigmoid-based hidden
; layers, and exposes per-digit (0-9) 
; classification confidence scores
commentEnd

constants env
; @pos 0 0
; @favorite
; Auto-generated environment constants
; Changes will be overwritten
; Last updated: 2/20/2026, 1:05:58 PM

const SAMPLE_RATE 50
const INV_SAMPLE_RATE 0.02
const AUDIO_BUFFER_SIZE 128

constantsEnd

module grid
; @pos -274 10
; @home 

; Draw the symbols
; you want to input into
; the neural network
; with 1s

int row0 0b0111
int row1 0b0100
int row2 0b0111
int row3 0b0101
int row4 0b0111

; Below you can read
; the confidence score
; of each digit the 
; network can recognise

moduleEnd

module inputs
; @pos -90 2
; Input layer

float64 input0 0.0f64
float64 input1 0.0f64
float64 input2 0.0f64
float64 input3 0.0f64
float64 input4 0.0f64
float64 input5 0.0f64
float64 input6 0.0f64
float64 input7 0.0f64
float64 input8 0.0f64
float64 input9 0.0f64
float64 input10 0.0f64
float64 input11 0.0f64
float64 input12 0.0f64
float64 input13 0.0f64
float64 input14 0.0f64

moduleEnd

module mask00
; @pos -221 -9

int* row &grid.row0
float64* input &inputs.input0

push input
push *row
push 2
shiftRight
castToFloat64
store

moduleEnd

module mask01
; @pos -185 -9

int* row &grid.row0
float64* input &inputs.input1

push input
push *row
push 0b010
and
push 1
shiftRight
castToFloat64
store

moduleEnd

module mask02
; @pos -149 -9

int* row &grid.row0
float64* input &inputs.input2

push input
push *row
push 0b001
and
castToFloat64
store

moduleEnd

module mask10
; @pos -221 7

int* row &grid.row1
float64* input &inputs.input3

push input
push *row
push 2
shiftRight
castToFloat64
store

moduleEnd

module mask11
; @pos -185 7

int* row &grid.row1
float64* input &inputs.input4

push input
push *row
push 0b010
and
push 1
shiftRight
castToFloat64
store

moduleEnd

module mask12
; @pos -149 7

int* row &grid.row1
float64* input &inputs.input5

push input
push *row
push 0b001
and
castToFloat64
store

moduleEnd

module mask20
; @pos -221 23

int* row &grid.row2
float64* input &inputs.input6

push input
push *row
push 2
shiftRight
castToFloat64
store

moduleEnd

module mask21
; @pos -185 23

int* row &grid.row2
float64* input &inputs.input7

push input
push *row
push 0b010
and
push 1
shiftRight
castToFloat64
store

moduleEnd

module mask22
; @pos -149 23

int* row &grid.row2
float64* input &inputs.input8

push input
push *row
push 0b001
and
castToFloat64
store

moduleEnd

module mask30
; @pos -221 39

int* row &grid.row3
float64* input &inputs.input9

push input
push *row
push 2
shiftRight
castToFloat64
store

moduleEnd

module mask31
; @pos -185 39

int* row &grid.row3
float64* input &inputs.input10

push input
push *row
push 0b010
and
push 1
shiftRight
castToFloat64
store

moduleEnd

module mask32
; @pos -149 39

int* row &grid.row3
float64* input &inputs.input11

push input
push *row
push 0b001
and
castToFloat64
store

moduleEnd

module mask40
; @pos -221 55

int* row &grid.row4
float64* input &inputs.input12

push input
push *row
push 2
shiftRight
castToFloat64
store

moduleEnd

module mask41
; @pos -185 55

int* row &grid.row4
float64* input &inputs.input13

push input
push *row
push 0b010
and
push 1
shiftRight
castToFloat64
store

moduleEnd

module mask42
; @pos -149 55

int* row &grid.row4
float64* input &inputs.input14

push input
push *row
push 0b001
and
castToFloat64
store

moduleEnd

module neuron100
; @pos 680 119
; Hidden layer 3

float64* in0 &neuron57.out
float64* in1 &neuron73.out
float64* in2 &neuron74.out
float64* in3 &neuron76.out
float64 out

; Weights
const W0 3.757478194135897f64
const W1 -7.047953084600809f64
const W2 -4.76401578156594f64
const W3 -4.553989343381097f64
const BIAS 6.250354239581638f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron101
; @pos 680 79
; Hidden layer 3

float64* in0 &neuron56.out
float64* in1 &neuron59.out
float64* in2 &neuron71.out
float64* in3 &neuron81.out
float64 out

; Weights
const W0 1.586981124469845f64
const W1 -5.519101547802804f64
const W2 5.736685178391028f64
const W3 0.5859389630080842f64
const BIAS 1.2807061660059844f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron102
; @pos 680 39
; Hidden layer 3

float64* in0 &neuron51.out
float64* in1 &neuron52.out
float64* in2 &neuron70.out
float64* in3 &neuron73.out
float64 out

; Weights
const W0 4.161569541968561f64
const W1 -3.1584049206497444f64
const W2 -4.893781011250167f64
const W3 8.976257540285689f64
const BIAS -0.14660158586186833f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron103
; @pos 680 -1
; Hidden layer 3

float64* in0 &neuron53.out
float64* in1 &neuron58.out
float64* in2 &neuron71.out
float64* in3 &neuron77.out
float64 out

; Weights
const W0 -0.023039573171386496f64
const W1 7.368106470476907f64
const W2 0.9403043683481166f64
const W3 -5.537118423549979f64
const BIAS 1.095974502669172f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron104
; @pos 680 -41
; Hidden layer 3

float64* in0 &neuron59.out
float64* in1 &neuron63.out
float64* in2 &neuron71.out
float64* in3 &neuron75.out
float64 out

; Weights
const W0 3.2264623726137605f64
const W1 7.741615137296449f64
const W2 -6.0887550830680555f64
const W3 1.0297403456117828f64
const BIAS -0.6929525309572981f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron105
; @pos 680 -81
; Hidden layer 3

float64* in0 &neuron59.out
float64* in1 &neuron64.out
float64* in2 &neuron67.out
float64* in3 &neuron77.out
float64 out

; Weights
const W0 3.261125822235786f64
const W1 -4.072596225669797f64
const W2 -1.038027659273711f64
const W3 -0.6957286145251012f64
const BIAS -0.4074278420634652f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron106
; @pos 720 39
; Hidden layer 3

float64* in0 &neuron53.out
float64* in1 &neuron59.out
float64* in2 &neuron68.out
float64* in3 &neuron72.out
float64 out

; Weights
const W0 -7.631298658396915f64
const W1 6.256774970415089f64
const W2 4.450451141525966f64
const W3 -5.844457840904865f64
const BIAS 5.301267901572463f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron107
; @pos 720 -1
; Hidden layer 3

float64* in0 &neuron58.out
float64* in1 &neuron60.out
float64* in2 &neuron68.out
float64* in3 &neuron75.out
float64 out

; Weights
const W0 -4.033837279562088f64
const W1 5.677227804195201f64
const W2 1.8983851549470583f64
const W3 -0.3756015047719981f64
const BIAS 0.8605601388044238f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron108
; @pos 800 119
; Output layer

float64* in0 &neuron91.out
float64* in1 &neuron94.out
float64* in2 &neuron96.out
float64* in3 &neuron97.out
float64 out

; Weights
const W0 -2.3673690733199244f64
const W1 -8.702424595773126f64
const W2 -9.050949708328051f64
const W3 10.268483557685212f64
const BIAS -0.2731448769659007f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron109
; @pos 800 79
; Output layer

float64* in0 &neuron93.out
float64* in1 &neuron98.out
float64* in2 &neuron105.out
float64* in3 &neuron106.out
float64 out

; Weights
const W0 1.2116952018518496f64
const W1 -12.938367522162872f64
const W2 -0.33996477091825783f64
const W3 3.919790659803682f64
const BIAS 2.0104087399286574f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron110
; @pos 800 39
; Output layer

float64* in0 &neuron86.out
float64* in1 &neuron90.out
float64* in2 &neuron99.out
float64* in3 &neuron103.out
float64 out

; Weights
const W0 0.6472555863898319f64
const W1 -0.9614163323565124f64
const W2 -9.330204943748551f64
const W3 -11.357487761479927f64
const BIAS 6.267483576584488f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron111
; @pos 800 -1
; Output layer

float64* in0 &neuron91.out
float64* in1 &neuron100.out
float64* in2 &neuron101.out
float64* in3 &neuron105.out
float64 out

; Weights
const W0 0.8712288362699737f64
const W1 -12.671090385111356f64
const W2 -10.045593143415728f64
const W3 4.642362674585975f64
const BIAS 4.078236614765328f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron112
; @pos 800 -41
; Output layer

float64* in0 &neuron82.out
float64* in1 &neuron88.out
float64* in2 &neuron104.out
float64* in3 &neuron107.out
float64 out

; Weights
const W0 -4.782825470153802f64
const W1 -5.0092617979584775f64
const W2 -10.309591821840186f64
const W3 5.644769413894911f64
const BIAS 1.798949350272586f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron113
; @pos 800 -81
; Output layer

float64* in0 &neuron88.out
float64* in1 &neuron89.out
float64* in2 &neuron99.out
float64* in3 &neuron102.out
float64 out

; Weights
const W0 6.471207910839414f64
const W1 -4.283687289788605f64
const W2 4.998223788621595f64
const W3 -13.748095060453167f64
const BIAS -1.4314905045815633f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron114
; @pos 840 79
; Output layer

float64* in0 &neuron84.out
float64* in1 &neuron85.out
float64* in2 &neuron90.out
float64* in3 &neuron105.out
float64 out

; Weights
const W0 5.596474717551611f64
const W1 0.24868344558829547f64
const W2 -11.727403650045108f64
const W3 -3.7385321049295706f64
const BIAS 0.26796086206958386f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron115
; @pos 840 39
; Output layer

float64* in0 &neuron84.out
float64* in1 &neuron85.out
float64* in2 &neuron87.out
float64* in3 &neuron106.out
float64 out

; Weights
const W0 6.664282273180268f64
const W1 1.9554414805917053f64
const W2 0.9986369169683056f64
const W3 -14.499874792234936f64
const BIAS 2.3226494706526375f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron116
; @pos 840 -1
; Output layer

float64* in0 &neuron83.out
float64* in1 &neuron91.out
float64* in2 &neuron92.out
float64* in3 &neuron107.out
float64 out

; Weights
const W0 -10.039030771099961f64
const W1 3.5054001081684887f64
const W2 -5.65856933557807f64
const W3 -5.811443881300278f64
const BIAS 5.194927539870348f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron117
; @pos 840 -41
; Output layer

float64* in0 &neuron89.out
float64* in1 &neuron95.out
float64* in2 &neuron102.out
float64* in3 &neuron104.out
float64 out

; Weights
const W0 7.837461185160993f64
const W1 -12.584398472167234f64
const W2 0.5877722921599581f64
const W3 6.504313348069712f64
const BIAS -3.21556616971869f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron15
; @pos 0 119
; Hidden layer 1

float64* in0 &inputs.input0
float64* in1 &inputs.input4
float64* in2 &inputs.input10
float64* in3 &inputs.input13
float64 out

; Weights
const W0 -1.1383185028099765f64
const W1 2.3440080019949394f64
const W2 2.1477626241632297f64
const W3 -2.465537689117045f64
const BIAS 0.5220812845884777f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron16
; @pos 0 79
; Hidden layer 1

float64* in0 &inputs.input3
float64* in1 &inputs.input5
float64* in2 &inputs.input6
float64* in3 &inputs.input9
float64 out

; Weights
const W0 -7.479177359069729f64
const W1 5.133573335148248f64
const W2 -3.781190365732491f64
const W3 -0.7969228642652161f64
const BIAS 3.702573570465371f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron17
; @pos 0 39
; Hidden layer 1

float64* in0 &inputs.input0
float64* in1 &inputs.input7
float64* in2 &inputs.input9
float64* in3 &inputs.input10
float64 out

; Weights
const W0 -2.1633151584131767f64
const W1 0.9850002714327549f64
const W2 3.5881161363072565f64
const W3 1.977221606107273f64
const BIAS 0.39986174007856734f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron18
; @pos 0 -1
; Hidden layer 1

float64* in0 &inputs.input2
float64* in1 &inputs.input6
float64* in2 &inputs.input13
float64* in3 &inputs.input14
float64 out

; Weights
const W0 -1.1104892732427174f64
const W1 -2.818830966365173f64
const W2 0.16042312986820045f64
const W3 2.922311764679564f64
const BIAS -0.05824651003385975f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron19
; @pos 0 -41
; Hidden layer 1

float64* in0 &inputs.input0
float64* in1 &inputs.input3
float64* in2 &inputs.input7
float64* in3 &inputs.input12
float64 out

; Weights
const W0 4.259377714402604f64
const W1 -6.782171541832181f64
const W2 -3.439960295993986f64
const W3 -2.4508582878244467f64
const BIAS 0.8120383923502664f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron20
; @pos 0 -81
; Hidden layer 1

float64* in0 &inputs.input2
float64* in1 &inputs.input6
float64* in2 &inputs.input7
float64* in3 &inputs.input9
float64 out

; Weights
const W0 0.04485081549189279f64
const W1 -3.283108207618379f64
const W2 0.9182411225289913f64
const W3 -2.725476326343996f64
const BIAS 1.3144264972644213f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron21
; @pos 40 119
; Hidden layer 1

float64* in0 &inputs.input1
float64* in1 &inputs.input8
float64* in2 &inputs.input11
float64* in3 &inputs.input14
float64 out

; Weights
const W0 2.83921035736664f64
const W1 -4.831894209494541f64
const W2 -1.5427433644898825f64
const W3 6.817905319213538f64
const BIAS 0.9119714660501288f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron22
; @pos 40 79
; Hidden layer 1

float64* in0 &inputs.input2
float64* in1 &inputs.input3
float64* in2 &inputs.input7
float64* in3 &inputs.input14
float64 out

; Weights
const W0 -6.107360024573014f64
const W1 4.476404728247612f64
const W2 -0.692832964444643f64
const W3 2.334589501392796f64
const BIAS 1.7276828762664738f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron23
; @pos 40 39
; Hidden layer 1

float64* in0 &inputs.input3
float64* in1 &inputs.input6
float64* in2 &inputs.input11
float64* in3 &inputs.input13
float64 out

; Weights
const W0 -2.9225140682629873f64
const W1 2.189914482191779f64
const W2 2.663535662984523f64
const W3 3.149338103898678f64
const BIAS -4.169589307647652f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron24
; @pos 40 -1
; Hidden layer 1

float64* in0 &inputs.input4
float64* in1 &inputs.input6
float64* in2 &inputs.input10
float64* in3 &inputs.input12
float64 out

; Weights
const W0 -3.058638554485918f64
const W1 -3.218271751451761f64
const W2 -1.752033492448678f64
const W3 6.465952594830679f64
const BIAS -1.5866548795719846f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron25
; @pos 40 -41
; Hidden layer 1

float64* in0 &inputs.input4
float64* in1 &inputs.input5
float64* in2 &inputs.input10
float64* in3 &inputs.input13
float64 out

; Weights
const W0 -5.180643074439107f64
const W1 -1.1356490099351555f64
const W2 -0.10369583965250342f64
const W3 3.17204296879583f64
const BIAS -0.21537825613931147f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron26
; @pos 40 -81
; Hidden layer 1

float64* in0 &inputs.input0
float64* in1 &inputs.input1
float64* in2 &inputs.input3
float64* in3 &inputs.input7
float64 out

; Weights
const W0 -3.205275628385772f64
const W1 2.973874051093608f64
const W2 0.19675919615673665f64
const W3 6.282617148734759f64
const BIAS -4.578630643429726f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron27
; @pos 80 119
; Hidden layer 1

float64* in0 &inputs.input3
float64* in1 &inputs.input6
float64* in2 &inputs.input7
float64* in3 &inputs.input14
float64 out

; Weights
const W0 -1.9663599176068152f64
const W1 4.506186545039228f64
const W2 -4.7350233857830935f64
const W3 4.063377090880007f64
const BIAS -0.6908114987336945f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron28
; @pos 80 79
; Hidden layer 1

float64* in0 &inputs.input4
float64* in1 &inputs.input10
float64* in2 &inputs.input13
float64* in3 &inputs.input14
float64 out

; Weights
const W0 1.8138722820817328f64
const W1 5.345652782196696f64
const W2 4.174906326558239f64
const W3 -1.0975488959828121f64
const BIAS -1.7800852392250206f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron29
; @pos 80 39
; Hidden layer 1

float64* in0 &inputs.input0
float64* in1 &inputs.input5
float64* in2 &inputs.input9
float64* in3 &inputs.input10
float64 out

; Weights
const W0 3.3855708379924305f64
const W1 2.5865507899633906f64
const W2 -7.970176831025005f64
const W3 -0.1917404976390699f64
const BIAS -3.3841445818337457f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron30
; @pos 80 -1
; Hidden layer 1

float64* in0 &inputs.input5
float64* in1 &inputs.input8
float64* in2 &inputs.input9
float64* in3 &inputs.input11
float64 out

; Weights
const W0 3.9510117502834463f64
const W1 2.9037792939341585f64
const W2 5.69614817392264f64
const W3 2.329351508509217f64
const BIAS -6.974964475942946f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron31
; @pos 80 -41
; Hidden layer 1

float64* in0 &inputs.input3
float64* in1 &inputs.input5
float64* in2 &inputs.input8
float64* in3 &inputs.input13
float64 out

; Weights
const W0 -4.176655185971842f64
const W1 -4.339761827571469f64
const W2 -1.0405297257437964f64
const W3 3.3690660263357963f64
const BIAS 4.181496728302399f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron32
; @pos 80 -81
; Hidden layer 1

float64* in0 &inputs.input4
float64* in1 &inputs.input5
float64* in2 &inputs.input13
float64* in3 &inputs.input14
float64 out

; Weights
const W0 1.105427309057273f64
const W1 -1.7455775076674738f64
const W2 -1.6159405803960742f64
const W3 -3.7012862065745957f64
const BIAS 4.225647465279082f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron33
; @pos 120 119
; Hidden layer 1

float64* in0 &inputs.input3
float64* in1 &inputs.input4
float64* in2 &inputs.input6
float64* in3 &inputs.input10
float64 out

; Weights
const W0 -2.6161226189734097f64
const W1 -2.8528077321371925f64
const W2 2.324327715847279f64
const W3 -2.3051198158143578f64
const BIAS -0.9881846213800362f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron34
; @pos 120 79
; Hidden layer 1

float64* in0 &inputs.input1
float64* in1 &inputs.input5
float64* in2 &inputs.input7
float64* in3 &inputs.input14
float64 out

; Weights
const W0 2.812163703876991f64
const W1 -6.062982186002442f64
const W2 -0.9499613191215542f64
const W3 1.5722324167099178f64
const BIAS -1.0066053950683451f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron35
; @pos 120 39
; Hidden layer 1

float64* in0 &inputs.input1
float64* in1 &inputs.input2
float64* in2 &inputs.input10
float64* in3 &inputs.input11
float64 out

; Weights
const W0 -0.12375689707670424f64
const W1 -0.057217900215691855f64
const W2 0.1997943777898417f64
const W3 -0.3776965466003815f64
const BIAS -0.10288435469399042f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron36
; @pos 120 -1
; Hidden layer 1

float64* in0 &inputs.input1
float64* in1 &inputs.input2
float64* in2 &inputs.input5
float64* in3 &inputs.input11
float64 out

; Weights
const W0 1.8883910013477094f64
const W1 -3.1795325207242904f64
const W2 0.2396256411327048f64
const W3 -3.914113287042571f64
const BIAS 2.8059257167747567f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron37
; @pos 120 -41
; Hidden layer 1

float64* in0 &inputs.input3
float64* in1 &inputs.input7
float64* in2 &inputs.input8
float64* in3 &inputs.input9
float64 out

; Weights
const W0 2.642379845702539f64
const W1 -3.1644527148051704f64
const W2 1.7629804978140795f64
const W3 4.088859673580342f64
const BIAS -2.4074125657467693f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron38
; @pos 120 -81
; Hidden layer 1

float64* in0 &inputs.input1
float64* in1 &inputs.input9
float64* in2 &inputs.input10
float64* in3 &inputs.input13
float64 out

; Weights
const W0 0.1506687532134647f64
const W1 -3.9213911626200653f64
const W2 -5.130006115548747f64
const W3 1.9896598779331562f64
const BIAS 1.4782636237975892f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron39
; @pos 160 119
; Hidden layer 1

float64* in0 &inputs.input2
float64* in1 &inputs.input8
float64* in2 &inputs.input10
float64* in3 &inputs.input12
float64 out

; Weights
const W0 4.612821304168174f64
const W1 -1.9213512720629897f64
const W2 -2.55486160183832f64
const W3 -0.49924003645915876f64
const BIAS -1.4990813593986914f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron40
; @pos 160 79
; Hidden layer 1

float64* in0 &inputs.input2
float64* in1 &inputs.input6
float64* in2 &inputs.input7
float64* in3 &inputs.input14
float64 out

; Weights
const W0 3.4618912465179243f64
const W1 -2.5235349589442957f64
const W2 2.3493320291201027f64
const W3 1.6251849404681324f64
const BIAS 0.6660745615973219f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron41
; @pos 160 39
; Hidden layer 1

float64* in0 &inputs.input5
float64* in1 &inputs.input7
float64* in2 &inputs.input11
float64* in3 &inputs.input13
float64 out

; Weights
const W0 0.5292963827244619f64
const W1 -0.5564928129837629f64
const W2 0.2678851446919406f64
const W3 2.3835540286087484f64
const BIAS -1.137129095247858f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron42
; @pos 160 -1
; Hidden layer 1

float64* in0 &inputs.input1
float64* in1 &inputs.input7
float64* in2 &inputs.input10
float64* in3 &inputs.input11
float64 out

; Weights
const W0 -0.471116840962701f64
const W1 -1.7163368793152594f64
const W2 1.5106174434637674f64
const W3 1.2214829659106121f64
const BIAS -0.003861002969057276f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron43
; @pos 160 -41
; Hidden layer 1

float64* in0 &inputs.input1
float64* in1 &inputs.input3
float64* in2 &inputs.input6
float64* in3 &inputs.input9
float64 out

; Weights
const W0 3.875836752913605f64
const W1 -1.5608610975234676f64
const W2 -1.9823813425393315f64
const W3 -5.656240932563921f64
const BIAS 1.4332529097494175f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron44
; @pos 160 -81
; Hidden layer 1

float64* in0 &inputs.input1
float64* in1 &inputs.input7
float64* in2 &inputs.input8
float64* in3 &inputs.input12
float64 out

; Weights
const W0 -3.4159824808602437f64
const W1 3.28823541703233f64
const W2 3.165360499604767f64
const W3 0.8566910077885699f64
const BIAS -1.5840341854176163f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron45
; @pos 200 119
; Hidden layer 1

float64* in0 &inputs.input1
float64* in1 &inputs.input2
float64* in2 &inputs.input10
float64* in3 &inputs.input14
float64 out

; Weights
const W0 -1.020320184865573f64
const W1 -0.8477969354889067f64
const W2 2.8340713782611258f64
const W3 2.5262941136043087f64
const BIAS 0.48900603287237016f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron46
; @pos 200 79
; Hidden layer 1

float64* in0 &inputs.input4
float64* in1 &inputs.input7
float64* in2 &inputs.input10
float64* in3 &inputs.input13
float64 out

; Weights
const W0 -1.1942224368529384f64
const W1 -2.671488201475223f64
const W2 -3.6500687667214247f64
const W3 3.6397792244944123f64
const BIAS -1.9516731889279744f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron47
; @pos 200 39
; Hidden layer 1

float64* in0 &inputs.input0
float64* in1 &inputs.input4
float64* in2 &inputs.input8
float64* in3 &inputs.input13
float64 out

; Weights
const W0 2.175062803551527f64
const W1 -4.79681402901416f64
const W2 1.8082605673272636f64
const W3 -1.0188200929734466f64
const BIAS 0.39944866688728486f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron48
; @pos 200 -1
; Hidden layer 1

float64* in0 &inputs.input3
float64* in1 &inputs.input5
float64* in2 &inputs.input11
float64* in3 &inputs.input12
float64 out

; Weights
const W0 0.4627904634817805f64
const W1 -2.1307872797026124f64
const W2 0.009033145373913126f64
const W3 2.0931730659088545f64
const BIAS 0.9147682354018025f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron49
; @pos 200 -41
; Hidden layer 1

float64* in0 &inputs.input1
float64* in1 &inputs.input2
float64* in2 &inputs.input7
float64* in3 &inputs.input13
float64 out

; Weights
const W0 2.806023897476518f64
const W1 -0.7098951684357988f64
const W2 -1.8561327183775156f64
const W3 2.5760771811467125f64
const BIAS -1.6374607365232312f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron50
; @pos 200 -81
; Hidden layer 1

float64* in0 &inputs.input1
float64* in1 &inputs.input4
float64* in2 &inputs.input6
float64* in3 &inputs.input9
float64 out

; Weights
const W0 -6.177206397037313f64
const W1 0.2402472560468867f64
const W2 4.643405082294793f64
const W3 -2.824376617716171f64
const BIAS 0.15914279659585293f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron51
; @pos 280 119
; Hidden layer 2

float64* in0 &neuron21.out
float64* in1 &neuron22.out
float64* in2 &neuron29.out
float64* in3 &neuron43.out
float64 out

; Weights
const W0 7.508169577552545f64
const W1 -0.10305459564112736f64
const W2 -6.519294415284561f64
const W3 -6.599384315720677f64
const BIAS 0.2960707117274044f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron52
; @pos 280 79
; Hidden layer 2

float64* in0 &neuron32.out
float64* in1 &neuron33.out
float64* in2 &neuron40.out
float64* in3 &neuron46.out
float64 out

; Weights
const W0 2.5815131816476975f64
const W1 -4.7631006821357635f64
const W2 1.8738930613037057f64
const W3 -5.604335045043373f64
const BIAS -0.16526679514199089f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron53
; @pos 280 39
; Hidden layer 2

float64* in0 &neuron31.out
float64* in1 &neuron37.out
float64* in2 &neuron47.out
float64* in3 &neuron48.out
float64 out

; Weights
const W0 -5.098591717699961f64
const W1 4.403381271623172f64
const W2 6.275952528794369f64
const W3 0.4181336187202384f64
const BIAS -1.2631190581545029f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron54
; @pos 280 -1
; Hidden layer 2

float64* in0 &neuron15.out
float64* in1 &neuron17.out
float64* in2 &neuron25.out
float64* in3 &neuron38.out
float64 out

; Weights
const W0 -1.165097641317072f64
const W1 0.6793652286409468f64
const W2 -0.04166312698711244f64
const W3 -0.09115286631132946f64
const BIAS 0.10563067975978446f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron55
; @pos 280 -41
; Hidden layer 2

float64* in0 &neuron25.out
float64* in1 &neuron35.out
float64* in2 &neuron46.out
float64* in3 &neuron47.out
float64 out

; Weights
const W0 -2.299024388190367f64
const W1 0.28667298855926987f64
const W2 -1.1289203926345264f64
const W3 0.19890385228004603f64
const BIAS 0.7874594263213985f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron56
; @pos 280 -81
; Hidden layer 2

float64* in0 &neuron34.out
float64* in1 &neuron46.out
float64* in2 &neuron48.out
float64* in3 &neuron49.out
float64 out

; Weights
const W0 1.2781846581725098f64
const W1 -0.017259141366892897f64
const W2 0.7242838328866523f64
const W3 -1.2001985004673412f64
const BIAS 0.20378634745644325f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron57
; @pos 320 119
; Hidden layer 2

float64* in0 &neuron31.out
float64* in1 &neuron39.out
float64* in2 &neuron41.out
float64* in3 &neuron49.out
float64 out

; Weights
const W0 0.5359450330844205f64
const W1 0.27431426932671854f64
const W2 0.6537888545698253f64
const W3 0.15545447168964782f64
const BIAS 1.5722821122237673f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron58
; @pos 320 79
; Hidden layer 2

float64* in0 &neuron16.out
float64* in1 &neuron24.out
float64* in2 &neuron25.out
float64* in3 &neuron32.out
float64 out

; Weights
const W0 -4.615960376731606f64
const W1 -0.9171060562450355f64
const W2 -0.6043746125203093f64
const W3 5.589937698051508f64
const BIAS 1.7198151139082745f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron59
; @pos 320 39
; Hidden layer 2

float64* in0 &neuron19.out
float64* in1 &neuron25.out
float64* in2 &neuron27.out
float64* in3 &neuron48.out
float64 out

; Weights
const W0 -8.34825811818246f64
const W1 3.0713018601645583f64
const W2 2.562155380032987f64
const W3 -0.558071415735546f64
const BIAS 2.5535884917304714f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron60
; @pos 320 -1
; Hidden layer 2

float64* in0 &neuron15.out
float64* in1 &neuron34.out
float64* in2 &neuron48.out
float64* in3 &neuron50.out
float64 out

; Weights
const W0 2.6391354309987487f64
const W1 2.732347554694646f64
const W2 0.6708737735757575f64
const W3 3.1954755538030373f64
const BIAS -4.264698804226941f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron61
; @pos 320 -41
; Hidden layer 2

float64* in0 &neuron24.out
float64* in1 &neuron32.out
float64* in2 &neuron42.out
float64* in3 &neuron44.out
float64 out

; Weights
const W0 4.918723613778873f64
const W1 -0.6779522262640634f64
const W2 0.8242484667267352f64
const W3 -1.388084027958714f64
const BIAS -1.357587489471562f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron62
; @pos 320 -81
; Hidden layer 2

float64* in0 &neuron17.out
float64* in1 &neuron18.out
float64* in2 &neuron31.out
float64* in3 &neuron42.out
float64 out

; Weights
const W0  -5.066599350868912f64
const W1   3.788350326364443f64
const W2   0.07863275676906946f64
const W3  -1.7613381052023283f64
const BIAS 1.948911759936236f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron63
; @pos 360 119
; Hidden layer 2

float64* in0 &neuron27.out
float64* in1 &neuron44.out
float64* in2 &neuron47.out
float64* in3 &neuron50.out
float64 out

; Weights
const W0 -1.5147795011557459f64
const W1 -4.52870583406503f64
const W2 -0.5209243347639098f64
const W3 -7.780654942913241f64
const BIAS 4.959652872153874f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron64
; @pos 360 79
; Hidden layer 2

float64* in0 &neuron16.out
float64* in1 &neuron19.out
float64* in2 &neuron27.out
float64* in3 &neuron39.out
float64 out

; Weights
const W0 -2.516618856376174f64
const W1 2.5675017411691474f64
const W2 1.5369427114416834f64
const W3 -2.3628210912175627f64
const BIAS 0.7457392023166535f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron65
; @pos 360 39
; Hidden layer 2

float64* in0 &neuron18.out
float64* in1 &neuron24.out
float64* in2 &neuron36.out
float64* in3 &neuron50.out
float64 out

; Weights
const W0 0.6237603087048084f64
const W1 -2.4178663132417237f64
const W2 2.8225132583991925f64
const W3 -3.547657741113842f64
const BIAS 1.4021680641664254f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron66
; @pos 360 -1
; Hidden layer 2

float64* in0 &neuron25.out
float64* in1 &neuron27.out
float64* in2 &neuron32.out
float64* in3 &neuron37.out
float64 out

; Weights
const W0 1.438693793546532f64
const W1 1.956532682805938f64
const W2 3.7353797030515654f64
const W3 -3.847848273094799f64
const BIAS -1.9809335572117426f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron67
; @pos 360 -41
; Hidden layer 2

float64* in0 &neuron18.out
float64* in1 &neuron19.out
float64* in2 &neuron38.out
float64* in3 &neuron40.out
float64 out

; Weights
const W0 -3.787036039740706f64
const W1 -0.7260956649519262f64
const W2 3.2071794522196453f64
const W3 -5.149846619580584f64
const BIAS 1.7012109668831301f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron68
; @pos 360 -81
; Hidden layer 2

float64* in0 &neuron25.out
float64* in1 &neuron30.out
float64* in2 &neuron48.out
float64* in3 &neuron50.out
float64 out

; Weights
const W0 -4.6472203203933145f64
const W1 -0.6669569819794553f64
const W2 -1.1156455374369372f64
const W3 2.3529778278470808f64
const BIAS 0.8996491280583585f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron69
; @pos 400 119
; Hidden layer 2

float64* in0 &neuron15.out
float64* in1 &neuron20.out
float64* in2 &neuron34.out
float64* in3 &neuron49.out
float64 out

; Weights
const W0 3.1953875853590956f64
const W1 4.640551774332455f64
const W2 -7.269653060339512f64
const W3 1.1158688727070492f64
const BIAS 1.3114746421264125f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron70
; @pos 400 79
; Hidden layer 2

float64* in0 &neuron21.out
float64* in1 &neuron24.out
float64* in2 &neuron27.out
float64* in3 &neuron30.out
float64 out

; Weights
const W0 0.3774234378172061f64
const W1 3.4210911720600428f64
const W2 -7.235025182607234f64
const W3 -5.075966732409136f64
const BIAS 2.8342304513910586f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron71
; @pos 400 39
; Hidden layer 2

float64* in0 &neuron22.out
float64* in1 &neuron24.out
float64* in2 &neuron31.out
float64* in3 &neuron47.out
float64 out

; Weights
const W0 3.7282730015713f64
const W1 -7.84631946993754f64
const W2 -4.2700127320600405f64
const W3 2.1420743038504098f64
const BIAS 0.3323401632979049f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron72
; @pos 400 -1
; Hidden layer 2

float64* in0 &neuron16.out
float64* in1 &neuron23.out
float64* in2 &neuron30.out
float64* in3 &neuron39.out
float64 out

; Weights
const W0 4.693200137465278f64
const W1 -4.275157012166426f64
const W2 -7.047610083398479f64
const W3 3.7625426546111127f64
const BIAS 0.24258228921626218f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron73
; @pos 400 -41
; Hidden layer 2

float64* in0 &neuron16.out
float64* in1 &neuron25.out
float64* in2 &neuron36.out
float64* in3 &neuron41.out
float64 out

; Weights
const W0 9.05085510174141f64
const W1 -5.212084682937803f64
const W2 3.776789758068037f64
const W3 -1.9504564938385731f64
const BIAS -0.12656590844479593f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron74
; @pos 400 -81
; Hidden layer 2

float64* in0 &neuron22.out
float64* in1 &neuron28.out
float64* in2 &neuron29.out
float64* in3 &neuron38.out
float64 out

; Weights
const W0 -5.118169476161381f64
const W1 -6.7383698263306515f64
const W2 4.96555161601721f64
const W3 6.499840340127992f64
const BIAS 0.980883954437184f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron75
; @pos 440 119
; Hidden layer 2

float64* in0 &neuron19.out
float64* in1 &neuron33.out
float64* in2 &neuron42.out
float64* in3 &neuron49.out
float64 out

; Weights
const W0 -1.5340272072513466f64
const W1 -0.9270550002476776f64
const W2 -1.348842497106429f64
const W3 0.6383799546828149f64
const BIAS 1.3130751456558596f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron76
; @pos 440 79
; Hidden layer 2

float64* in0 &neuron22.out
float64* in1 &neuron28.out
float64* in2 &neuron36.out
float64* in3 &neuron49.out
float64 out

; Weights
const W0 -1.8489232589720694f64
const W1 -1.829835861365709f64
const W2 -4.85275829479159f64
const W3 4.0780778522499f64
const BIAS 0.723319813394505f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron77
; @pos 440 39
; Hidden layer 2

float64* in0 &neuron18.out
float64* in1 &neuron26.out
float64* in2 &neuron39.out
float64* in3 &neuron47.out
float64 out

; Weights
const W0 0.8990565833517322f64
const W1 3.555710174197911f64
const W2 -3.695412232947725f64
const W3 2.3574389336998505f64
const BIAS -1.6486549776259025f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron78
; @pos 440 -1
; Hidden layer 2

float64* in0 &neuron29.out
float64* in1 &neuron36.out
float64* in2 &neuron44.out
float64* in3 &neuron46.out
float64 out

; Weights
const W0 -2.3245994633977975f64
const W1 -3.0684030106938747f64
const W2 2.4850505463783024f64
const W3 -0.8602000639848378f64
const BIAS -0.11483486183972066f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron79
; @pos 440 -41
; Hidden layer 2

float64* in0 &neuron15.out
float64* in1 &neuron30.out
float64* in2 &neuron39.out
float64* in3 &neuron44.out
float64 out

; Weights
const W0 0.6132231393938841f64
const W1 -0.7625872674833064f64
const W2 0.6055858297397931f64
const W3 -2.2847787028597697f64
const BIAS 0.5750149785379238f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron80
; @pos 440 -81
; Hidden layer 2

float64* in0 &neuron22.out
float64* in1 &neuron29.out
float64* in2 &neuron30.out
float64* in3 &neuron41.out
float64 out

; Weights
const W0 2.4446329335126173f64
const W1 -3.116175154040148f64
const W2 2.3829088071719915f64
const W3 -0.19845933840896615f64
const BIAS -2.3058209606359257f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron81
; @pos 480 19
; Hidden layer 2

float64* in0 &neuron26.out
float64* in1 &neuron31.out
float64* in2 &neuron37.out
float64* in3 &neuron45.out
float64 out

; Weights
const W0 -8.195448354064249f64
const W1 6.356235180084015f64
const W2 3.255594512990857f64
const W3 3.873995042814291f64
const BIAS -0.7308008218981984f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron82
; @pos 560 119
; Hidden layer 3

float64* in0 &neuron54.out
float64* in1 &neuron58.out
float64* in2 &neuron65.out
float64* in3 &neuron69.out
float64 out

; Weights
const W0 0.7334657222118448f64
const W1 0.9634464368264306f64
const W2 3.6595013758094255f64
const W3 -1.6249495792249489f64
const BIAS -1.6128045209246384f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron83
; @pos 560 79
; Hidden layer 3

float64* in0 &neuron61.out
float64* in1 &neuron66.out
float64* in2 &neuron78.out
float64* in3 &neuron80.out
float64 out

; Weights
const W0 5.01994345131093f64
const W1 5.286725370064507f64
const W2 -4.2691104514039875f64
const W3 -3.19205699772642f64
const BIAS -0.04605259180740309f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron84
; @pos 560 39
; Hidden layer 3

float64* in0 &neuron52.out
float64* in1 &neuron60.out
float64* in2 &neuron62.out
float64* in3 &neuron81.out
float64 out

; Weights
const W0 1.1338694824152538f64
const W1 3.5710723961961386f64
const W2 -5.880462409999788f64
const W3 1.9189409836904499f64
const BIAS -0.35343900075862517f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron85
; @pos 560 -1
; Hidden layer 3

float64* in0 &neuron53.out
float64* in1 &neuron57.out
float64* in2 &neuron60.out
float64* in3 &neuron79.out
float64 out

; Weights
const W0 0.5674249148966389f64
const W1 -1.136564282172089f64
const W2 0.5257854012227227f64
const W3 1.6427213086562034f64
const BIAS -0.719778284685272f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron86
; @pos 560 -41
; Hidden layer 3

float64* in0 &neuron59.out
float64* in1 &neuron61.out
float64* in2 &neuron65.out
float64* in3 &neuron75.out
float64 out

; Weights
const W0 -0.0670516208256435f64
const W1 -1.0945824379790534f64
const W2 0.24575732777850795f64
const W3 -0.17234136738674308f64
const BIAS 0.004124753114218049f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron87
; @pos 560 -81
; Hidden layer 3

float64* in0 &neuron58.out
float64* in1 &neuron63.out
float64* in2 &neuron66.out
float64* in3 &neuron68.out
float64 out

; Weights
const W0 0.44315762439752215f64
const W1 0.6970436792547057f64
const W2 -0.28712501999650525f64
const W3 -0.2113146095182074f64
const BIAS -0.6525996344299397f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron88
; @pos 600 119
; Hidden layer 3

float64* in0 &neuron64.out
float64* in1 &neuron67.out
float64* in2 &neuron71.out
float64* in3 &neuron73.out
float64 out

; Weights
const W0 -0.5379044806557166f64
const W1 -0.7315861402747185f64
const W2 -6.4527556550082235f64
const W3 0.30098353577736386f64
const BIAS 1.783380839050354f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron89
; @pos 600 79
; Hidden layer 3

float64* in0 &neuron65.out
float64* in1 &neuron70.out
float64* in2 &neuron74.out
float64* in3 &neuron81.out
float64 out

; Weights
const W0 2.7723537797651514f64
const W1 -6.012187399375749f64
const W2 -2.2705123070156943f64
const W3 -7.2732524398030485f64
const BIAS 4.1108165954170754f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron90
; @pos 600 39
; Hidden layer 3

float64* in0 &neuron51.out
float64* in1 &neuron67.out
float64* in2 &neuron69.out
float64* in3 &neuron74.out
float64 out

; Weights
const W0 -5.161071978828384f64
const W1 4.58867022472783f64
const W2 7.253726783054169f64
const W3 4.178742914458397f64
const BIAS -1.4354383626638334f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron91
; @pos 600 -1
; Hidden layer 3

float64* in0 &neuron57.out
float64* in1 &neuron64.out
float64* in2 &neuron80.out
float64* in3 &neuron81.out
float64 out

; Weights
const W0 -0.5733612071082838f64
const W1 -0.772049921618484f64
const W2 2.319163949765651f64
const W3 -3.192546309661814f64
const BIAS -0.45947605237174105f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron92
; @pos 600 -41
; Hidden layer 3

float64* in0 &neuron51.out
float64* in1 &neuron53.out
float64* in2 &neuron79.out
float64* in3 &neuron81.out
float64 out

; Weights
const W0 -3.373420882262691f64
const W1 -1.6086678198638344f64
const W2 1.7209938290668638f64
const W3 5.576713992827989f64
const BIAS 0.2562118033394713f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron93
; @pos 600 -81
; Hidden layer 3

float64* in0 &neuron54.out
float64* in1 &neuron62.out
float64* in2 &neuron65.out
float64* in3 &neuron78.out
float64 out

; Weights
const W0 -0.19650250573495961f64
const W1 0.781458744101778f64
const W2 -0.2675702423700327f64
const W3 0.24328802383186973f64
const BIAS -0.030817843184623134f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron94
; @pos 640 119
; Hidden layer 3

float64* in0 &neuron52.out
float64* in1 &neuron62.out
float64* in2 &neuron67.out
float64* in3 &neuron77.out
float64 out

; Weights
const W0 3.1837669531235666f64
const W1 4.59107130028303f64
const W2 -4.672355293966502f64
const W3 -0.077555755895608f64
const BIAS -1.6505900054195874f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron95
; @pos 640 79
; Hidden layer 3

float64* in0 &neuron51.out
float64* in1 &neuron52.out
float64* in2 &neuron55.out
float64* in3 &neuron72.out
float64 out

; Weights
const W0 12.204018966809462f64
const W1 -2.2029266451300598f64
const W2 -2.1309184588679315f64
const W3 6.454820377554602f64
const BIAS -0.2876600591991529f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron96
; @pos 640 39
; Hidden layer 3

float64* in0 &neuron52.out
float64* in1 &neuron63.out
float64* in2 &neuron72.out
float64* in3 &neuron76.out
float64 out

; Weights
const W0 3.48163185824482f64
const W1 -5.394804862300504f64
const W2 3.331976354297626f64
const W3 0.9850410346830718f64
const BIAS 1.1806833021011243f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron97
; @pos 640 -1
; Hidden layer 3

float64* in0 &neuron59.out
float64* in1 &neuron69.out
float64* in2 &neuron71.out
float64* in3 &neuron75.out
float64 out

; Weights
const W0 -1.7344940469038082f64
const W1 4.376004773357256f64
const W2 5.30270636818833f64
const W3 -1.1110515116443251f64
const BIAS -1.4958436439417517f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron98
; @pos 640 -41
; Hidden layer 3

float64* in0 &neuron53.out
float64* in1 &neuron60.out
float64* in2 &neuron73.out
float64* in3 &neuron74.out
float64 out

; Weights
const W0 7.500210415879902f64
const W1 -2.137253777173839f64
const W2 -5.017330188732944f64
const W3 0.29489654286372396f64
const BIAS 2.524378433819746f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module neuron99
; @pos 640 -81
; Hidden layer 3

float64* in0 &neuron53.out
float64* in1 &neuron56.out
float64* in2 &neuron69.out
float64* in3 &neuron74.out
float64 out

; Weights
const W0 -3.730862374274342f64
const W1 0.8369943557266591f64
const W2 -0.7678776240692549f64
const W3 6.766040510688673f64
const BIAS 0.005137788756736317f64

push &out
push BIAS
push *in0
push W0
mul
add
push *in1
push W1
mul
add
push *in2
push W2
mul
add
push *in3
push W3
mul
add
call sigmoid
store

moduleEnd

module outputs
; @pos -274 33

; Confidence scores:
; @debug *confidence0
; @debug *confidence1
; @debug *confidence2
; @debug *confidence3
; @debug *confidence4
; @debug *confidence5
; @debug *confidence6
; @debug *confidence7
; @debug *confidence8
; @debug *confidence9

; Routing the values of the output 
; neurons here into this module
float64* confidence0 &neuron108.out
float64* confidence1 &neuron109.out
float64* confidence2 &neuron110.out
float64* confidence3 &neuron111.out
float64* confidence4 &neuron112.out
float64* confidence5 &neuron113.out
float64* confidence6 &neuron114.out
float64* confidence7 &neuron115.out
float64* confidence8 &neuron116.out
float64* confidence9 &neuron117.out

moduleEnd

function sigmoid
; @pos -326 38
param float64 x
; Fast sigmoid approximation
; of logistic sigmoid
; mapped to [0, 1]

localGet x
dup
abs
push 1.0f64
add
ensureNonZero
div
push 0.5f64
mul
push 0.5f64
add

functionEnd float64